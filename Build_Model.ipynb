{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Sunny Again        Work Tomorrow  :-|  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>handed in my uniform today . i miss you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>I must think about positive..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>thanks to all the haters up in my face a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>this weekend has sucked so far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>jb isnt showing in australia any more!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>ok thats it you win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;-------- This is the way i feel right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>awhhe man.... I'm completely useless rt no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Feeling strangely fine. Now I'm gonna go l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>HUGE roll of thunder just now...SO scary!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>I just cut my beard off. It's only been gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>Very sad about Iran.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>wompppp wompp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>You're the only one who can see this cause...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;---Sad level is 3. I was writing a mass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>...  Headed to Hospitol : Had to pull out o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>BoRinG   ): whats wrong with him??     Plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>can't be bothered. i wish i could spend the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>Feeeling like shit right now. I really want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>goodbye exams, HELLO ALCOHOL TONIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>I didn't realize it was THAT deep. Geez giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578582</th>\n",
       "      <td>1</td>\n",
       "      <td>zoo was rad today. feeling tired and not motiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578583</th>\n",
       "      <td>1</td>\n",
       "      <td>Zoo with the woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578584</th>\n",
       "      <td>0</td>\n",
       "      <td>zoolander and alice in wonderland. i have a ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578585</th>\n",
       "      <td>1</td>\n",
       "      <td>Zoom zoom! Back to bristol today I have my bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578586</th>\n",
       "      <td>0</td>\n",
       "      <td>zootm: cannot survive without CRLF support  - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578587</th>\n",
       "      <td>0</td>\n",
       "      <td>Zoran lost Croatian Idol!  The difference was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578588</th>\n",
       "      <td>0</td>\n",
       "      <td>Zork. Buggy beta version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578589</th>\n",
       "      <td>1</td>\n",
       "      <td>Zow, finished uploading pictures on Flickr and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578590</th>\n",
       "      <td>1</td>\n",
       "      <td>Zrock was awesome!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578591</th>\n",
       "      <td>1</td>\n",
       "      <td>ZTecWiz bought mIRC for $10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578592</th>\n",
       "      <td>1</td>\n",
       "      <td>'Zu SpÃ¤t' by Die Ã„rzte. One of the best band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578593</th>\n",
       "      <td>1</td>\n",
       "      <td>Zuma bitch tomorrow. Have a wonderful night ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578594</th>\n",
       "      <td>0</td>\n",
       "      <td>zummie's couch tour was amazing....to bad i ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578595</th>\n",
       "      <td>0</td>\n",
       "      <td>ZuneHD looks great! OLED screen @720p, HDMI, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578596</th>\n",
       "      <td>1</td>\n",
       "      <td>zup there ! learning a new magic trick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578597</th>\n",
       "      <td>1</td>\n",
       "      <td>zyklonic showers   *evil*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578598</th>\n",
       "      <td>1</td>\n",
       "      <td>ZZ Top â€“ I Thank You ...@hawaiibuzz   .....T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578599</th>\n",
       "      <td>0</td>\n",
       "      <td>zzz time. Just wish my love could B nxt 2 me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578600</th>\n",
       "      <td>1</td>\n",
       "      <td>zzz twitter. good day today. got a lot accompl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578601</th>\n",
       "      <td>1</td>\n",
       "      <td>zzz's time, goodnight.  http://plurk.com/p/ri9qn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578602</th>\n",
       "      <td>0</td>\n",
       "      <td>Zzzz lying in bed watching the countryside thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578603</th>\n",
       "      <td>1</td>\n",
       "      <td>Zzzz... Fuck Ã¼ : Zzzz... Fuck Ã¼  http://bit....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578604</th>\n",
       "      <td>1</td>\n",
       "      <td>Zzzz...no work tomorrow..yayyy!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578605</th>\n",
       "      <td>1</td>\n",
       "      <td>ZZZZZ time.. Tomorrow will be a busy day for s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578606</th>\n",
       "      <td>0</td>\n",
       "      <td>Zzzzz want to sleep but at sister's in-laws's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578607</th>\n",
       "      <td>1</td>\n",
       "      <td>Zzzzzz.... Finally! Night tweeters!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578608</th>\n",
       "      <td>1</td>\n",
       "      <td>Zzzzzzz, sleep well people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578609</th>\n",
       "      <td>0</td>\n",
       "      <td>ZzzZzZzzzZ... wait no I have homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578610</th>\n",
       "      <td>0</td>\n",
       "      <td>ZzZzzzZZZZzzz meh, what am I doing up again?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578611</th>\n",
       "      <td>0</td>\n",
       "      <td>Zzzzzzzzzzzzzzzzzzz, I wish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1578612 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                      SentimentText\n",
       "0                0                       is so sad for my APL frie...\n",
       "1                0                     I missed the New Moon trail...\n",
       "2                1                            omg its already 7:30 :O\n",
       "3                0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4                0           i think mi bf is cheating on me!!!   ...\n",
       "5                0                  or i just worry too much?        \n",
       "6                1                 Juuuuuuuuuuuuuuuuussssst Chillin!!\n",
       "7                0         Sunny Again        Work Tomorrow  :-|  ...\n",
       "8                1        handed in my uniform today . i miss you ...\n",
       "9                1           hmmmm.... i wonder how she my number @-)\n",
       "10               0                      I must think about positive..\n",
       "11               1        thanks to all the haters up in my face a...\n",
       "12               0                     this weekend has sucked so far\n",
       "13               0             jb isnt showing in australia any more!\n",
       "14               0                               ok thats it you win.\n",
       "15               0      &lt;-------- This is the way i feel right ...\n",
       "16               0      awhhe man.... I'm completely useless rt no...\n",
       "17               1      Feeling strangely fine. Now I'm gonna go l...\n",
       "18               0       HUGE roll of thunder just now...SO scary!!!!\n",
       "19               0      I just cut my beard off. It's only been gr...\n",
       "20               0                               Very sad about Iran.\n",
       "21               0                                      wompppp wompp\n",
       "22               1      You're the only one who can see this cause...\n",
       "23               0     &lt;---Sad level is 3. I was writing a mass...\n",
       "24               0     ...  Headed to Hospitol : Had to pull out o...\n",
       "25               0     BoRinG   ): whats wrong with him??     Plea...\n",
       "26               0     can't be bothered. i wish i could spend the...\n",
       "27               0     Feeeling like shit right now. I really want...\n",
       "28               1              goodbye exams, HELLO ALCOHOL TONIGHT \n",
       "29               0     I didn't realize it was THAT deep. Geez giv...\n",
       "...            ...                                                ...\n",
       "1578582          1  zoo was rad today. feeling tired and not motiv...\n",
       "1578583          1                                Zoo with the woman \n",
       "1578584          0  zoolander and alice in wonderland. i have a ki...\n",
       "1578585          1  Zoom zoom! Back to bristol today I have my bea...\n",
       "1578586          0  zootm: cannot survive without CRLF support  - ...\n",
       "1578587          0  Zoran lost Croatian Idol!  The difference was ...\n",
       "1578588          0                          Zork. Buggy beta version \n",
       "1578589          1  Zow, finished uploading pictures on Flickr and...\n",
       "1578590          1                               Zrock was awesome!! \n",
       "1578591          1                       ZTecWiz bought mIRC for $10 \n",
       "1578592          1  'Zu SpÃ¤t' by Die Ã„rzte. One of the best band...\n",
       "1578593          1  Zuma bitch tomorrow. Have a wonderful night ev...\n",
       "1578594          0  zummie's couch tour was amazing....to bad i ha...\n",
       "1578595          0  ZuneHD looks great! OLED screen @720p, HDMI, o...\n",
       "1578596          1            zup there ! learning a new magic trick \n",
       "1578597          1                          zyklonic showers   *evil*\n",
       "1578598          1  ZZ Top â€“ I Thank You ...@hawaiibuzz   .....T...\n",
       "1578599          0      zzz time. Just wish my love could B nxt 2 me \n",
       "1578600          1  zzz twitter. good day today. got a lot accompl...\n",
       "1578601          1   zzz's time, goodnight.  http://plurk.com/p/ri9qn\n",
       "1578602          0  Zzzz lying in bed watching the countryside thr...\n",
       "1578603          1  Zzzz... Fuck Ã¼ : Zzzz... Fuck Ã¼  http://bit....\n",
       "1578604          1                  Zzzz...no work tomorrow..yayyy!! \n",
       "1578605          1  ZZZZZ time.. Tomorrow will be a busy day for s...\n",
       "1578606          0  Zzzzz want to sleep but at sister's in-laws's ...\n",
       "1578607          1               Zzzzzz.... Finally! Night tweeters! \n",
       "1578608          1                        Zzzzzzz, sleep well people \n",
       "1578609          0            ZzzZzZzzzZ... wait no I have homework. \n",
       "1578610          0      ZzZzzzZZZZzzz meh, what am I doing up again? \n",
       "1578611          0                       Zzzzzzzzzzzzzzzzzzz, I wish \n",
       "\n",
       "[1578612 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Sentiment Analysis Dataset.csv\", skiprows = [8835, 535881], usecols = [1, 3])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = list(data['SentimentText'])\n",
    "y = list(data['Sentiment'])\n",
    "train_x, val_x, train_y, val_y = train_test_split(x, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new Tokenizer that finds the 3000 most popular words found in our dataset\n",
    "tokenizer = Tokenizer(num_words = 3000)\n",
    "tokenizer.fit_on_texts(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = tokenizer.word_index\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_WordIndices = []\n",
    "# This converts strings of text into lists of index array\n",
    "for text in train_x:\n",
    "    wordIndices = [dictionary[word] for word in text_to_word_sequence(text)]\n",
    "    train_WordIndices.append(wordIndices)\n",
    "\n",
    "train_WordIndices_arr = np.asarray(train_WordIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([2289, 6, 5374]),\n",
       "       list([33685, 139, 24, 118, 11, 4, 174, 203, 1, 114, 58, 145, 596, 10, 4, 13248, 133]),\n",
       "       list([113674, 69, 898, 3344, 306, 1, 33, 82, 16, 5497, 47, 38, 3300, 38, 6093]),\n",
       "       ...,\n",
       "       list([3804, 1419, 1419, 569812, 8, 20, 61, 2, 270, 31, 3, 77, 3786, 229, 2148, 244, 53, 59, 78, 9, 544, 270, 267, 33, 53, 20049, 123, 72, 58, 16, 50]),\n",
       "       list([20, 361, 28, 51, 4, 683, 4142]),\n",
       "       list([13377, 60, 142, 4335, 6, 477, 187])], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_WordIndices_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create matrices out of the indexed tweets\n",
    "# tokenizer.sequences_to_matrix returns a numpy matrix of (len(allWordindices), 3000)\n",
    "train_x = tokenizer.sequences_to_matrix(train_WordIndices_arr, mode='binary')\n",
    "train_y = keras.utils.to_categorical(train_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(3000,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1065563 samples, validate on 118396 samples\n",
      "Epoch 1/5\n",
      "1065563/1065563 [==============================] - 187s 176us/step - loss: 0.4548 - acc: 0.7878 - val_loss: 0.4357 - val_acc: 0.7993\n",
      "Epoch 2/5\n",
      "1065563/1065563 [==============================] - 186s 175us/step - loss: 0.4266 - acc: 0.8060 - val_loss: 0.4277 - val_acc: 0.8043\n",
      "Epoch 3/5\n",
      "1065563/1065563 [==============================] - 186s 175us/step - loss: 0.4148 - acc: 0.8140 - val_loss: 0.4279 - val_acc: 0.8052\n",
      "Epoch 4/5\n",
      "1065563/1065563 [==============================] - 186s 175us/step - loss: 0.4067 - acc: 0.8199 - val_loss: 0.4270 - val_acc: 0.8042\n",
      "Epoch 5/5\n",
      "1065563/1065563 [==============================] - 186s 175us/step - loss: 0.4009 - acc: 0.8237 - val_loss: 0.4282 - val_acc: 0.8061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f049ae3b630>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=32, epochs=5, verbose=1, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([294937, 504]),\n",
       "       list([397, 545, 247, 13, 382, 132, 4, 851, 85, 8985, 9, 190025, 182, 21, 794, 18, 382, 96, 20, 4680, 742, 8985]),\n",
       "       list([431, 808, 744, 51560, 9956, 6, 96, 1, 300, 16, 4, 3044]), ...,\n",
       "       list([184, 39, 57, 5085, 5085, 8680, 10275, 5085, 13123, 65, 16111, 13123, 103, 65, 5014, 1273, 65, 1898, 160, 65, 1024, 16111, 13123, 479167]),\n",
       "       list([46787, 413, 47, 5, 1717, 318, 4, 30, 105, 277, 194, 8, 381, 15, 58, 67, 719, 31, 413, 244, 7, 210, 59, 871, 85, 17, 8]),\n",
       "       list([825, 25, 4, 1804, 12, 50])], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation\n",
    "val_WordIndices = []\n",
    "\n",
    "def sentence_to_words(text) :\n",
    "    wordIndices = []\n",
    "    arr_word = text_to_word_sequence(text)\n",
    "    for word in arr_word:\n",
    "        if word in dictionary:\n",
    "            wordIndices.append(dictionary[word])\n",
    "    return wordIndices\n",
    "            \n",
    "# This converts strings of text into lists of index array\n",
    "for text in val_x:\n",
    "    val_WordIndices.append(sentence_to_words(text))\n",
    "\n",
    "val_WordIndices_arr = np.asarray(val_WordIndices)\n",
    "val_WordIndices_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_x = tokenizer.sequences_to_matrix(val_WordIndices_arr, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y = model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0518201 ,  0.94817984],\n",
       "       [ 0.63616741,  0.36383253],\n",
       "       [ 0.13913073,  0.86086929],\n",
       "       ..., \n",
       "       [ 0.08002418,  0.91997582],\n",
       "       [ 0.0986807 ,  0.90131932],\n",
       "       [ 0.57361299,  0.42638701]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y1 = keras.utils.to_categorical(val_y, 2)\n",
    "val_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80600172810038184"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(val_y1, pred_y.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate this:if you dont give up, you still have a chance. Giving up is the greatest failure\n",
      "positive sentiment; 74.754125% confidence\n",
      "Evaluate this:Chase interesting, work on things that matter\n",
      "positive sentiment; 95.394254% confidence\n",
      "Evaluate this:Today is hard. tomorrow will be worse, but the day after tomorrow will be sunshine.\n",
      "negative sentiment; 63.721722% confidence\n",
      "Evaluate this:When I am myself, I am happy and have a good result.\n",
      "positive sentiment; 97.670412% confidence\n",
      "Evaluate this:You are bad\n",
      "negative sentiment; 57.280171% confidence\n",
      "Evaluate this:Your attitude is everything\n",
      "positive sentiment; 67.119724% confidence\n",
      "Evaluate this:The very important thing you should have is patience\n",
      "positive sentiment; 96.641892% confidence\n",
      "Evaluate this:I love neural network\n",
      "positive sentiment; 93.712616% confidence\n",
      "Evaluate this:\n"
     ]
    }
   ],
   "source": [
    "tokenizer2 = Tokenizer(num_words=3000)\n",
    "labels = ['negative', 'positive']\n",
    "while True:\n",
    "    text_input = input('Evaluate this:')\n",
    "    if len(text_input) == 0:\n",
    "        break\n",
    "    words_input = sentence_to_words(text_input)\n",
    "    input1 = tokenizer2.sequences_to_matrix([words_input], mode='binary')\n",
    "    pred = model.predict(input1)\n",
    "    print(\"%s sentiment; %f%% confidence\" % (labels[np.argmax(pred)], pred[0][np.argmax(pred)] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
